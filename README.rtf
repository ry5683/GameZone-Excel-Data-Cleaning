{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # GameZone Sales Data: A Data Cleaning Project in Google Sheets/Excel\
\
## Project Objective\
\
This project demonstrates the process of cleaning and preparing raw sales data for analysis. The goal was to take inconsistent, messy transactional data from multiple sources and transform it into a single, reliable dataset ready for reporting and analysis. All data cleaning and transformation were performed exclusively using Google Sheets/Microsoft Excel.\
\
## The Data\
\
The project uses three main files:\
* **Orders Data:** Contains individual transaction records, including product details, customer information, and shipping times.\
* **Region Data:** A lookup table mapping country codes to sales regions.\
* **Issues Log:** A summary of all data quality issues identified and the steps taken to resolve them.\
\
## Tools Used\
\
* **Google Sheets / Microsoft Excel:** For all data manipulation, cleaning, and validation tasks. Key functions and tools used include `VLOOKUP`/`XLOOKUP`, `TRIM`, `PROPER`, Text to Columns, conditional formatting for duplicate detection, and pivot tables for validation.\
* **Git & GitHub:** For version control and project documentation.\
\
## The Data Cleaning Process\
\
The raw data presented several challenges that would make accurate analysis impossible. I identified and resolved these issues systematically. The full list of problems and solutions is documented in the `issues_log.csv` file.\
\
Below is a summary of the key cleaning steps I performed:\
\
### 1. Standardized Naming Conventions\
* **Problem:** The `PRODUCT_NAME` column contained several variations for the same item (e.g., "PS5 Console", "Playstation 5", "Sony PS5").\
* **Solution:** Created a standardization map and used `VLOOKUP` to apply a single, consistent name for each product.\
\
### 2. Corrected Data Types and Formats\
* **Problem:** The `ORDER_DATE` was stored as text in multiple formats (e.g., "MM-DD-YY", "YYYY/MM/DD"). The `PRICE` column contained currency symbols and was stored as text.\
* **Solution:** Used the Text to Columns feature and date formatting tools to convert all dates to a standard `YYYY-MM-DD` format. Removed currency symbols and converted the `PRICE` column to a numeric type.\
\
### 3. Handled Missing and Inconsistent Data\
* **Problem:** Several records were missing a `CUSTOMER_ID`. The `COUNTRY` column had both full names ("United States") and abbreviations ("USA").\
* **Solution:** For the purpose of this cleaning exercise, rows with missing `CUSTOMER_ID` were flagged for review. Country names were standardized to the two-letter ISO code to prepare for joining with the region data.\
\
### 4. Enriched Data by Joining Datasets\
* **Problem:** The main orders file contained a country code but not the broader sales region (e.g., EMEA, NA).\
* **Solution:** Used `VLOOKUP` to join the orders data with the region data based on the country code, adding a `REGION` column to every transaction. This allows for region-based performance analysis.\
\
## Project Outcome\
\
The result of this process is a clean, reliable, and analysis-ready dataset located in the `/02_cleaned_data/` folder. The "before" and "after" can be seen by comparing the files in the `/01_raw_data/` and `/02_cleaned_data/` directories.\
\
This clean data now enables accurate analysis through tools like Excel Pivot Tables, SQL, or BI platforms like Tableau.}